import{d as V,A as x,b as j,c as H,f as W,g as K,h as E,i as J,j as Y,a as F,k as ee,l as te,m as se,n as oe,o as ne,p as ie,q as ae,r as re,s as le,t as ce,u as pe,v as de,w as ue,x as me,y as M,z as C,B as q,C as fe,D as he,E as D,F as _e,R as S,T as B,G as ge,H as ye,e as R}from"./image-O15s_1zf.js";import{A,r as ke}from"./processors-De2tF4GJ.js";import{a as we,T as xe}from"./config-hvj4ggRh.js";async function I(s){return Array.isArray(s)||(s=[s]),await Promise.all(s.map(e=>S.read(e)))}async function X(s,e){return Array.isArray(s)||(s=[s]),await Promise.all(s.map(t=>typeof t=="string"||t instanceof URL?ke(t,e):t instanceof Float64Array?new Float32Array(t):t))}function N(s,e){e&&(s=s.map(i=>i|0));const[t,o,n,r]=s;return{xmin:t,ymin:o,xmax:n,ymax:r}}class y extends ye{constructor({task:e,model:t,tokenizer:o=null,processor:n=null}){super(),this.task=e,this.model=t,this.tokenizer=o,this.processor=n}async dispose(){await this.model.dispose()}}class be extends y{constructor(e){super(e)}async _call(e,{topk:t=1}={}){const o=this.tokenizer(e,{padding:!0,truncation:!0}),n=await this.model(o),r=this.model.config.problem_type==="multi_label_classification"?c=>c.sigmoid().data:c=>M(c.data),i=this.model.config.id2label,a=[];for(const c of n.logits){const d=r(c),m=C(d,t).map(u=>({label:i[u[0]],score:u[1]}));t===1?a.push(...m):a.push(m)}return Array.isArray(e)||t===1?a:a[0]}}class Ae extends y{constructor(e){super(e)}async _call(e,{ignore_labels:t=["O"]}={}){const o=Array.isArray(e),n=this.tokenizer(o?e:[e],{padding:!0,truncation:!0}),i=(await this.model(n)).logits,a=this.model.config.id2label,c=[];for(let d=0;d<i.dims[0];++d){const p=n.input_ids[d],m=i[d],u=[];for(let l=0;l<m.dims[0];++l){const f=m[l],h=q(f.data)[1],g=a?a[h]:`LABEL_${h}`;if(t.includes(g))continue;const _=this.tokenizer.decode([p[l].item()],{skip_special_tokens:!0});if(_==="")continue;const k=M(f.data);u.push({entity:g,score:k[h],index:l,word:_,start:null,end:null})}c.push(u)}return o?c:c[0]}}class ve extends y{constructor(e){super(e)}async _call(e,t,{topk:o=1}={}){const n=this.tokenizer(e,{text_pair:t,padding:!0,truncation:!0}),r=await this.model(n),i=[];for(let a=0;a<r.start_logits.dims[0];++a){const c=n.input_ids[a],d=c.indexOf(this.tokenizer.sep_token_id),p=Array.from(M(r.start_logits[a].data)).map((l,f)=>[l,f]).filter(l=>l[1]>d),m=Array.from(M(r.end_logits[a].data)).map((l,f)=>[l,f]).filter(l=>l[1]>d),u=fe(p,m).filter(l=>l[0][1]<=l[1][1]).map(l=>[l[0][1],l[1][1],l[0][0]*l[1][0]]).sort((l,f)=>f[2]-l[2]);for(let l=0;l<Math.min(u.length,o);++l){const[f,h,g]=u[l],_=[...c].slice(f,h+1),k=this.tokenizer.decode(_,{skip_special_tokens:!0});i.push({answer:k,score:g})}}return o===1?i[0]:i}}class ze extends y{constructor(e){super(e)}async _call(e,{topk:t=5}={}){const o=this.tokenizer(e,{padding:!0,truncation:!0}),n=await this.model(o),r=[];for(let i=0;i<o.input_ids.dims[0];++i){const a=o.input_ids[i],c=a.indexOf(this.tokenizer.mask_token_id);if(c===-1)throw Error(`Mask token (${this.tokenizer.mask_token}) not found in text.`);const p=n.logits[i][c],m=C(M(p.data),t);r.push(m.map(u=>{const l=[...a];return l[c]=u[0],{score:u[1],token:u[0],token_str:this.tokenizer.model.vocab[u[0]],sequence:this.tokenizer.decode(l,{skip_special_tokens:!0})}}))}return Array.isArray(e)?r:r[0]}}class O extends y{_key="generated_text";constructor(e){super(e)}async _call(e,t={}){Array.isArray(e)||(e=[e]),this.model.config.prefix&&(e=e.map(c=>this.model.config.prefix+c));const o=this.model.config.task_specific_params;o&&o[this.task]&&o[this.task].prefix&&(e=e.map(c=>o[this.task].prefix+c));const n=this.tokenizer,r={padding:!0,truncation:!0};let i;this instanceof Z&&"_build_translation_inputs"in n?i=n._build_translation_inputs(e,r,t).input_ids:i=n(e,r).input_ids;const a=await this.model.generate(i,t);return n.batch_decode(a,{skip_special_tokens:!0}).map(c=>({[this._key]:c}))}}class Te extends O{_key="summary_text";constructor(e){super(e)}}class Z extends O{_key="translation_text";constructor(e){super(e)}}class Me extends y{constructor(e){super(e)}async _call(e,t={}){const o=Array.isArray(e);o||(e=[e]);const n=t.add_special_tokens??!1;this.tokenizer.padding_side="left";const{input_ids:r,attention_mask:i}=this.tokenizer(e,{add_special_tokens:n,padding:!0,truncation:!0}),a=await this.model.generate(r,t,null,{inputs_attention_mask:i}),c=this.tokenizer.batch_decode(a,{skip_special_tokens:!0}),d=Array.from({length:e.length},p=>[]);for(let p=0;p<c.length;++p){const m=Math.floor(p/a.length*e.length);d[m].push({generated_text:c[p]})}return!o&&d.length===1?d[0]:d}}class Ie extends y{constructor(e){super(e),this.label2id=Object.fromEntries(Object.entries(this.model.config.label2id).map(([t,o])=>[t.toLowerCase(),o])),this.entailment_id=this.label2id.entailment,this.entailment_id===void 0&&(console.warn("Could not find 'entailment' in label2id mapping. Using 2 as entailment_id."),this.entailment_id=2),this.contradiction_id=this.label2id.contradiction??this.label2id.not_entailment,this.contradiction_id===void 0&&(console.warn("Could not find 'contradiction' in label2id mapping. Using 0 as contradiction_id."),this.contradiction_id=0)}async _call(e,t,{hypothesis_template:o="This example is {}.",multi_label:n=!1}={}){const r=Array.isArray(e);r||(e=[e]),Array.isArray(t)||(t=[t]);const i=t.map(d=>o.replace("{}",d)),a=n||t.length===1,c=[];for(const d of e){const p=[];for(const l of i){const f=this.tokenizer(d,{text_pair:l,padding:!0,truncation:!0}),h=await this.model(f);a?p.push([h.logits.data[this.contradiction_id],h.logits.data[this.entailment_id]]):p.push(h.logits.data[this.entailment_id])}const u=(a?p.map(l=>M(l)[1]):M(p)).map((l,f)=>[l,f]).sort((l,f)=>f[0]-l[0]);c.push({sequence:d,labels:u.map(l=>t[l[1]]),scores:u.map(l=>l[0])})}return r?c:c[0]}}class Pe extends y{constructor(e){super(e)}async _call(e,{pooling:t="none",normalize:o=!1}={}){const n=this.tokenizer(e,{padding:!0,truncation:!0}),r=await this.model(n);let i=r.last_hidden_state??r.logits;if(t!=="none")if(t==="mean")i=he(i,n.attention_mask);else if(t==="cls")i=i.slice(null,0);else throw Error(`Pooling method '${t}' not supported.`);return o&&(i=i.normalize(2,-1)),i}}class Fe extends y{constructor(e){super(e)}async _call(e,{pool:t=null}={}){const o=await I(e),{pixel_values:n}=await this.processor(o),r=await this.model({pixel_values:n});let i;if(t){if(!("pooler_output"in r))throw Error("No pooled output was returned. Make sure the model has a 'pooler' layer when using the 'pool' option.");i=r.pooler_output}else i=r.last_hidden_state??r.logits??r.image_embeds;return i}}class Se extends y{constructor(e){super(e)}async _call(e,{topk:t=null}={}){const o=!Array.isArray(e),n=this.processor.feature_extractor.config.sampling_rate,r=await X(e,n),i=this.model.config.id2label,a=[];for(const c of r){const d=await this.processor(c),m=(await this.model(d)).logits[0],l=C(M(m.data),t).map(f=>({label:i[f[0]],score:f[1]}));t===1?a.push(...l):a.push(l)}return!o||t===1?a:a[0]}}class Re extends y{constructor(e){super(e)}async _call(e,t,{hypothesis_template:o="This is a sound of {}."}={}){const n=!Array.isArray(e);n&&(e=[e]);const r=t.map(p=>o.replace("{}",p)),i=this.tokenizer(r,{padding:!0,truncation:!0}),a=this.processor.feature_extractor.config.sampling_rate,c=await X(e,a),d=[];for(const p of c){const m=await this.processor(p),u=await this.model({...i,...m}),l=M(u.logits_per_audio.data);d.push([...l].map((f,h)=>({score:f,label:t[h]})))}return n?d[0]:d}}class Xe extends y{constructor(e){super(e)}async _call(e,t={}){switch(this.model.config.model_type){case"whisper":return this._call_whisper(e,t);case"wav2vec2":case"wav2vec2-bert":case"unispeech":case"unispeech-sat":case"hubert":return this._call_wav2vec2(e,t);default:throw new Error(`AutomaticSpeechRecognitionPipeline does not support model type '${this.model.config.model_type}'.`)}}async _call_wav2vec2(e,t={}){t.language&&console.warn('`language` parameter is not yet supported for `wav2vec2` models, defaulting to "English".'),t.task&&console.warn('`task` parameter is not yet supported for `wav2vec2` models, defaulting to "transcribe".');const o=!Array.isArray(e);o&&(e=[e]);const n=this.processor.feature_extractor.config.sampling_rate,r=await X(e,n),i=[];for(const a of r){const c=await this.processor(a),p=(await this.model(c)).logits[0],m=[];for(const l of p)m.push(q(l.data)[1]);const u=this.tokenizer.decode(m);i.push({text:u})}return o?i[0]:i}async _call_whisper(e,t={}){const o=t.return_timestamps??!1,n=t.chunk_length_s??0,r=t.chunk_callback??null,i=t.force_full_sequences??!1;let a=t.stride_length_s??null;o==="word"&&(t.return_token_timestamps=!0);const c=D(t,"language",null),d=D(t,"task",null);if(c||d||o){if(t.forced_decoder_ids)throw new Error("Cannot specify `language`/`task`/`return_timestamps` and `forced_decoder_ids` at the same time.");const g=this.tokenizer.get_decoder_prompt_ids({language:c,task:d,no_timestamps:!o});g.length>0&&(t.forced_decoder_ids=g)}const p=!Array.isArray(e);p&&(e=[e]);const m=this.processor.feature_extractor.config.chunk_length/this.model.config.max_source_positions,u=this.processor.feature_extractor.config.hop_length,l=this.processor.feature_extractor.config.sampling_rate,f=await X(e,l),h=[];for(const g of f){let _=[];if(n>0){if(a===null)a=n/6;else if(n<=a)throw Error("`chunk_length_s` must be larger than `stride_length_s`.");const w=l*n,T=l*a,b=w-2*T;let P=0;for(;P<g.length;){const U=g.subarray(P,P+w),G=await this.processor(U),Q=P===0,L=P+b>=g.length;_.push({stride:[U.length,Q?0:T,L?0:T],input_features:G.input_features,is_last:L}),P+=b}}else _=[{stride:[g.length,0,0],input_features:(await this.processor(g)).input_features,is_last:!0}];for(const w of _){t.num_frames=Math.floor(w.stride[0]/u);const T=await this.model.generate(w.input_features,t);o==="word"?(w.tokens=T.sequences[0],w.token_timestamps=T.token_timestamps.tolist()[0].map(b=>_e(b,2))):w.tokens=T[0],w.stride=w.stride.map(b=>b/l),r!==null&&r(w)}const[k,z]=this.tokenizer._decode_asr(_,{time_precision:m,return_timestamps:o,force_full_sequences:i});h.push({text:k,...z})}return p?h[0]:h}}class Ce extends y{constructor(e){super(e)}async _call(e,t={}){const o=Array.isArray(e),n=await I(e),{pixel_values:r}=await this.processor(n),i=[];for(const a of r){a.dims=[1,...a.dims];const c=await this.model.generate(a,t),d=this.tokenizer.batch_decode(c,{skip_special_tokens:!0}).map(p=>({generated_text:p.trim()}));i.push(d)}return o?i:i[0]}}class Ee extends y{constructor(e){super(e)}async _call(e,{topk:t=1}={}){const o=Array.isArray(e),n=await I(e),{pixel_values:r}=await this.processor(n),i=await this.model({pixel_values:r}),a=this.model.config.id2label,c=[];for(const d of i.logits){const m=C(M(d.data),t).map(u=>({label:a[u[0]],score:u[1]}));t===1?c.push(...m):c.push(m)}return o||t===1?c:c[0]}}class qe extends y{constructor(e){super(e),this.subtasks_mapping={panoptic:"post_process_panoptic_segmentation",instance:"post_process_instance_segmentation",semantic:"post_process_semantic_segmentation"}}async _call(e,{threshold:t=.5,mask_threshold:o=.5,overlap_mask_area_threshold:n=.8,label_ids_to_fuse:r=null,target_sizes:i=null,subtask:a=null}={}){if(Array.isArray(e)&&e.length!==1)throw Error("Image segmentation pipeline currently only supports a batch size of 1.");const d=await I(e),p=d.map(_=>[_.height,_.width]),{pixel_values:m,pixel_mask:u}=await this.processor(d),l=await this.model({pixel_values:m,pixel_mask:u});let f=null;if(a!==null)f=this.subtasks_mapping[a];else for(let[_,k]of Object.entries(this.subtasks_mapping))if(k in this.processor.feature_extractor){f=this.processor.feature_extractor[k].bind(this.processor.feature_extractor),a=_;break}const h=this.model.config.id2label,g=[];if(a==="panoptic"||a==="instance"){const _=f(l,t,o,n,r,i??p)[0],k=_.segmentation;for(const z of _.segments_info){const w=new Uint8ClampedArray(k.data.length);for(let b=0;b<k.data.length;++b)k.data[b]===z.id&&(w[b]=255);const T=new S(w,k.dims[1],k.dims[0],1);g.push({score:z.score,label:h[z.label_id],mask:T})}}else if(a==="semantic"){const{segmentation:_,labels:k}=f(l,i??p)[0];for(const z of k){const w=new Uint8ClampedArray(_.data.length);for(let b=0;b<_.data.length;++b)_.data[b]===z&&(w[b]=255);const T=new S(w,_.dims[1],_.dims[0],1);g.push({score:null,label:h[z],mask:T})}}else throw Error(`Subtask ${a} not supported.`);return g}}class Oe extends y{constructor(e){super(e)}async _call(e,t,{hypothesis_template:o="This is a photo of {}"}={}){const n=Array.isArray(e),r=await I(e),i=t.map(u=>o.replace("{}",u)),a=this.tokenizer(i,{padding:this.model.config.model_type==="siglip"?"max_length":!0,truncation:!0}),{pixel_values:c}=await this.processor(r),d=await this.model({...a,pixel_values:c}),p=this.model.config.model_type==="siglip"?u=>u.sigmoid().data:u=>M(u.data),m=[];for(const u of d.logits_per_image){const f=[...p(u)].map((h,g)=>({score:h,label:t[g]}));f.sort((h,g)=>g.score-h.score),m.push(f)}return n?m:m[0]}}class Ue extends y{constructor(e){super(e)}async _call(e,{threshold:t=.9,percentage:o=!1}={}){const n=Array.isArray(e);if(n&&e.length!==1)throw Error("Object detection pipeline currently only supports a batch size of 1.");const r=await I(e),i=o?null:r.map(l=>[l.height,l.width]),{pixel_values:a,pixel_mask:c}=await this.processor(r),d=await this.model({pixel_values:a,pixel_mask:c}),p=this.processor.feature_extractor.post_process_object_detection(d,t,i),m=this.model.config.id2label,u=p.map(l=>l.boxes.map((f,h)=>({score:l.scores[h],label:m[l.classes[h]],box:N(f,!o)})));return n?u:u[0]}}class Le extends y{constructor(e){super(e)}async _call(e,t,{threshold:o=.1,topk:n=null,percentage:r=!1}={}){const i=Array.isArray(e),a=await I(e),c=this.tokenizer(t,{padding:!0,truncation:!0}),d=await this.processor(a),p=[];for(let m=0;m<a.length;++m){const u=a[m],l=r?null:[[u.height,u.width]],f=d.pixel_values[m].unsqueeze_(0),h=await this.model({...c,pixel_values:f}),g=this.processor.feature_extractor.post_process_object_detection(h,o,l,!0)[0];let _=g.boxes.map((k,z)=>({score:g.scores[z],label:t[g.classes[z]],box:N(k,!r)})).sort((k,z)=>z.score-k.score);n!==null&&(_=_.slice(0,n)),p.push(_)}return i?p:p[0]}}class je extends y{constructor(e){super(e)}async _call(e,t,o={}){const n=(await I(e))[0],{pixel_values:r}=await this.processor(n),i=`<s_docvqa><s_question>${t}</s_question><s_answer>`,a=this.tokenizer(i,{add_special_tokens:!1,padding:!0,truncation:!0}).input_ids,c=await this.model.generate(r,{...o,decoder_input_ids:a,max_length:this.model.config.decoder.max_position_embeddings}),p=this.tokenizer.batch_decode(c)[0].match(/<s_answer>(.*?)<\/s_answer>/);let m=null;return p&&p.length>=2&&(m=p[1].trim()),[{answer:m}]}}class De extends y{DEFAULT_VOCODER_ID="Xenova/speecht5_hifigan";constructor(e){super(e),this.vocoder=e.vocoder??null}async _call(e,{speaker_embeddings:t=null}={}){return this.processor?this._call_text_to_spectrogram(e,{speaker_embeddings:t}):this._call_text_to_waveform(e)}async _call_text_to_waveform(e){const t=this.tokenizer(e,{padding:!0,truncation:!0}),{waveform:o}=await this.model(t),n=this.model.config.sampling_rate;return{audio:o.data,sampling_rate:n}}async _call_text_to_spectrogram(e,{speaker_embeddings:t}){if(this.vocoder||(console.log("No vocoder specified, using default HifiGan vocoder."),this.vocoder=await F.from_pretrained(this.DEFAULT_VOCODER_ID,{dtype:"fp32"})),(typeof t=="string"||t instanceof URL)&&(t=new Float32Array(await(await fetch(t)).arrayBuffer())),t instanceof Float32Array)t=new B("float32",t,[1,t.length]);else if(!(t instanceof B))throw new Error("Speaker embeddings must be a `Tensor`, `Float32Array`, `string`, or `URL`.");const{input_ids:o}=this.tokenizer(e,{padding:!0,truncation:!0}),{waveform:n}=await this.model.generate_speech(o,t,{vocoder:this.vocoder}),r=this.processor.feature_extractor.config.sampling_rate;return{audio:n.data,sampling_rate:r}}}class Be extends y{constructor(e){super(e)}async _call(e){const t=await I(e),o=await this.processor(t),n=await this.model(o),r=[];for(const i of n.reconstruction){const a=i.squeeze().clamp_(0,1).mul_(255).round_().to("uint8");r.push(S.fromTensor(a))}return r.length>1?r:r[0]}}class $e extends y{constructor(e){super(e)}async _call(e){const t=await I(e),o=await this.processor(t),{predicted_depth:n}=await this.model(o),r=[];for(let i=0;i<t.length;++i){const a=ge(n[i],t[i].size.reverse(),"bilinear",!1),c=a.mul_(255/q(a.data)[0]).to("uint8");r.push({predicted_depth:n[i],depth:S.fromTensor(c)})}return r.length>1?r:r[0]}}const $=Object.freeze({"text-classification":{tokenizer:x,pipeline:be,model:j,default:{model:"Xenova/distilbert-base-uncased-finetuned-sst-2-english"},type:"text"},"token-classification":{tokenizer:x,pipeline:Ae,model:H,default:{model:"Xenova/bert-base-multilingual-cased-ner-hrl"},type:"text"},"question-answering":{tokenizer:x,pipeline:ve,model:W,default:{model:"Xenova/distilbert-base-cased-distilled-squad"},type:"text"},"fill-mask":{tokenizer:x,pipeline:ze,model:K,default:{model:"Xenova/bert-base-uncased"},type:"text"},summarization:{tokenizer:x,pipeline:Te,model:E,default:{model:"Xenova/distilbart-cnn-6-6"},type:"text"},translation:{tokenizer:x,pipeline:Z,model:E,default:{model:"Xenova/t5-small"},type:"text"},"text2text-generation":{tokenizer:x,pipeline:O,model:E,default:{model:"Xenova/flan-t5-small"},type:"text"},"text-generation":{tokenizer:x,pipeline:Me,model:J,default:{model:"Xenova/gpt2"},type:"text"},"zero-shot-classification":{tokenizer:x,pipeline:Ie,model:j,default:{model:"Xenova/distilbert-base-uncased-mnli"},type:"text"},"audio-classification":{pipeline:Se,model:Y,processor:A,default:{model:"Xenova/wav2vec2-base-superb-ks"},type:"audio"},"zero-shot-audio-classification":{tokenizer:x,pipeline:Re,model:F,processor:A,default:{model:"Xenova/clap-htsat-unfused"},type:"multimodal"},"automatic-speech-recognition":{tokenizer:x,pipeline:Xe,model:[ee,te],processor:A,default:{model:"Xenova/whisper-tiny.en"},type:"multimodal"},"text-to-audio":{tokenizer:x,pipeline:De,model:[se,oe],processor:[A,null],default:{model:"Xenova/speecht5_tts"},type:"text"},"image-to-text":{tokenizer:x,pipeline:Ce,model:ne,processor:A,default:{model:"Xenova/vit-gpt2-image-captioning"},type:"multimodal"},"image-classification":{pipeline:Ee,model:ie,processor:A,default:{model:"Xenova/vit-base-patch16-224"},type:"multimodal"},"image-segmentation":{pipeline:qe,model:[ae,re],processor:A,default:{model:"Xenova/detr-resnet-50-panoptic"},type:"multimodal"},"zero-shot-image-classification":{tokenizer:x,pipeline:Oe,model:F,processor:A,default:{model:"Xenova/clip-vit-base-patch32"},type:"multimodal"},"object-detection":{pipeline:Ue,model:le,processor:A,default:{model:"Xenova/detr-resnet-50"},type:"multimodal"},"zero-shot-object-detection":{tokenizer:x,pipeline:Le,model:ce,processor:A,default:{model:"Xenova/owlvit-base-patch32"},type:"multimodal"},"document-question-answering":{tokenizer:x,pipeline:je,model:pe,processor:A,default:{model:"Xenova/donut-base-finetuned-docvqa"},type:"multimodal"},"image-to-image":{pipeline:Be,model:de,processor:A,default:{model:"Xenova/swin2SR-classical-sr-x2-64"},type:"image"},"depth-estimation":{pipeline:$e,model:ue,processor:A,default:{model:"Xenova/dpt-large"},type:"image"},"feature-extraction":{tokenizer:x,pipeline:Pe,model:F,default:{model:"Xenova/all-MiniLM-L6-v2"},type:"text"},"image-feature-extraction":{processor:A,pipeline:Fe,model:[me,F],default:{model:"Xenova/vit-base-patch16-224-in21k"},type:"image"}}),Ne=Object.freeze({"sentiment-analysis":"text-classification",ner:"token-classification",asr:"automatic-speech-recognition","text-to-speech":"text-to-audio",embeddings:"feature-extraction"});async function Ze(s,e=null,{progress_callback:t=null,config:o=null,cache_dir:n=null,local_files_only:r=!1,revision:i="main",device:a=null,dtype:c=null,session_options:d={}}={}){s=Ne[s]??s;const p=$[s.split("_",1)[0]];if(!p)throw Error(`Unsupported pipeline: ${s}. Must be one of [${Object.keys($)}]`);e||(e=p.default.model,console.log(`No model specified. Using default model: "${e}".`));const m={progress_callback:t,config:o,cache_dir:n,local_files_only:r,revision:i,device:a,dtype:c,session_options:d},u=new Map([["tokenizer",p.tokenizer],["model",p.model],["processor",p.processor]]),l=await Ge(u,e,m);l.task=s,V(t,{status:"ready",task:s,model:e});const f=p.pipeline;return new f(l)}async function Ge(s,e,t){const o=Object.create(null),n=[];for(let[r,i]of s.entries()){if(!i)continue;let a;Array.isArray(i)?a=new Promise(async(c,d)=>{let p;for(let m of i){if(m===null){c(null);return}try{c(await m.from_pretrained(e,t));return}catch(u){if(u.message?.includes("Unsupported model type"))p=u;else{d(u);return}}}d(p)}):a=i.from_pretrained(e,t),o[r]=a,n.push(a)}await Promise.all(n);for(let[r,i]of Object.entries(o))o[r]=await i;return o}R.allowLocalModels=!0,R.allowRemoteModels=!1;const Qe={translation:lt,"text-generation":ct,"code-completion":pt,"masked-language-modelling":dt,"sequence-classification":ut,"token-classification":mt,"zero-shot-classification":ft,"question-answering":ht,summarization:_t,"automatic-speech-recognition":gt,"image-to-text":yt,"image-classification":kt,"zero-shot-image-classification":wt,"object-detection":xt};self.addEventListener("message",async s=>{const{baseURI:e}=s.data;e&&(R.localModelPath=new URL(e).origin+we,R.backends.onnx.wasm.wasmPaths=new URL(e).origin+xe);const t=s.data;let o=Qe[t.task];if(!o)return;let n=await o(t);self.postMessage({task:t.task,type:"result",data:n})});class v{static task=null;static model=null;static instance=null;constructor(e,t){this.tokenizer=e,this.model=t}static getInstance(e=null){if(this.task===null||this.model===null)throw Error("Must set task and model");return this.instance===null&&(this.instance=Ze(this.task,this.model,{progress_callback:e})),this.instance}}class Ve extends v{static task="translation";static model="Xenova/t5-small"}class He extends v{static task="text-generation";static model="Xenova/distilgpt2"}class We extends v{static task="text-generation";static model="Xenova/codegen-350M-mono"}class Ke extends v{static task="fill-mask";static model="Xenova/bert-base-cased"}class Je extends v{static task="text-classification";static model="Xenova/bert-base-multilingual-uncased-sentiment"}class Ye extends v{static task="token-classification";static model="Xenova/bert-base-multilingual-cased-ner-hrl"}class et extends v{static task="zero-shot-classification";static model="Xenova/distilbert-base-uncased-mnli"}class tt extends v{static task="question-answering";static model="Xenova/distilbert-base-cased-distilled-squad"}class st extends v{static task="summarization";static model="Xenova/distilbart-cnn-6-6"}class ot extends v{static task="automatic-speech-recognition";static model="Xenova/whisper-tiny.en"}class nt extends v{static task="image-to-text";static model="Xenova/vit-gpt2-image-captioning"}class it extends v{static task="image-classification";static model="Xenova/vit-base-patch16-224"}class at extends v{static task="zero-shot-image-classification";static model="Xenova/clip-vit-base-patch16"}class rt extends v{static task="object-detection";static model="Xenova/detr-resnet-50"}async function lt(s){let e=await Ve.getInstance(t=>{self.postMessage({type:"download",task:"translation",data:t})});return e.task=`translation_${s.languageFrom}_to_${s.languageTo}`,await e(s.text,{...s.generation,callback_function:function(t){const o=e.tokenizer.decode(t[0].output_token_ids,{skip_special_tokens:!0});self.postMessage({type:"update",target:s.elementIdToUpdate,data:o})}})}async function ct(s){let e=await He.getInstance(o=>{self.postMessage({type:"download",task:"text-generation",data:o})}),t=s.text.trim();return await e(t,{...s.generation,callback_function:function(o){const n=e.tokenizer.decode(o[0].output_token_ids,{skip_special_tokens:!0});self.postMessage({type:"update",target:s.elementIdToUpdate,data:n})}})}async function pt(s){let e=await We.getInstance(o=>{self.postMessage({type:"download",task:"code-completion",data:o})}),t=s.text;return await e(t,{...s.generation,callback_function:function(o){const n=e.tokenizer.decode(o[0].output_token_ids,{skip_special_tokens:!0});self.postMessage({type:"update",target:s.elementIdToUpdate,targetType:s.targetType,data:n})}})}async function dt(s){let t=await(await Ke.getInstance(o=>{self.postMessage({type:"download",task:"masked-language-modelling",data:o})}))(s.text,s.generation);return self.postMessage({type:"update",target:s.elementIdToUpdate,data:t.map(o=>o.sequence).join(`
`)}),t}async function ut(s){let t=await(await Je.getInstance(o=>{self.postMessage({type:"download",task:"sequence-classification",data:o})}))(s.text,{topk:5});self.postMessage({type:"complete",target:s.elementIdToUpdate,targetType:s.targetType,data:t})}async function mt(s){let e=await Ye.getInstance(i=>{self.postMessage({type:"download",task:"token-classification",data:i})}),t=await e(s.text,{ignore_labels:[]}),o=[],n={type:"",text:[]};for(let i=0;i<t.length;i++){let a=e.tokenizer.model.tokens_to_ids.get(t[i].word),c=t[i].entity;c.startsWith("B-")?(n.text.length>0&&(o.push(n),n={type:"",text:[]}),n.type=c.slice(2),n.text=[a]):c.startsWith("I-")?n.text.push(a):n.text.length>0?n.type==="O"?n.text.push(a):(o.push(n),n={type:"O",text:[a]}):n={type:"O",text:[a]}}n.text.length>0&&o.push(n);let r=o.map(i=>({type:i.type,text:e.tokenizer.decode(i.text)}));self.postMessage({type:"complete",target:s.elementIdToUpdate,targetType:s.targetType,data:r})}async function ft(s){let t=await(await et.getInstance(n=>{self.postMessage({type:"download",task:"zero-shot-classification",data:n})}))(s.text,s.classes,s.generation),o=t.labels.map((n,r)=>({label:n,score:t.scores[r]}));self.postMessage({type:"complete",target:s.elementIdToUpdate,targetType:s.targetType,data:o})}async function ht(s){let t=await(await tt.getInstance(o=>{self.postMessage({type:"download",task:"question-answering",data:o})}))(s.question,s.context);return self.postMessage({type:"complete",target:s.elementIdToUpdate,data:t.answer}),t}async function _t(s){let e=await st.getInstance(t=>{self.postMessage({type:"download",task:"summarization",data:t})});return await e(s.text,{...s.generation,callback_function:function(t){const o=e.tokenizer.decode(t[0].output_token_ids,{skip_special_tokens:!0});self.postMessage({type:"update",target:s.elementIdToUpdate,data:o.trim()})}})}async function gt(s){let e=await ot.getInstance(t=>{self.postMessage({type:"download",task:"automatic-speech-recognition",data:t})});return await e(s.audio,{chunk_length_s:30,stride_length_s:5,...s.generation,callback_function:function(t){const o=e.tokenizer.decode(t[0].output_token_ids,{skip_special_tokens:!0});self.postMessage({type:"update",target:s.elementIdToUpdate,data:o.trim()})}})}async function yt(s){let e=await nt.getInstance(t=>{self.postMessage({type:"download",task:"image-to-text",data:t})});return await e(s.image,{...s.generation,callback_function:function(t){const o=e.tokenizer.decode(t[0].output_token_ids,{skip_special_tokens:!0});self.postMessage({type:"update",target:s.elementIdToUpdate,data:o.trim()})}})}async function kt(s){let t=await(await it.getInstance(o=>{self.postMessage({type:"download",task:"image-classification",data:o})}))(s.image,{topk:5});self.postMessage({type:"complete",target:s.elementIdToUpdate,targetType:s.targetType,updateLabels:s.updateLabels,data:t})}async function wt(s){let t=await(await at.getInstance(o=>{self.postMessage({type:"download",task:"image-classification",data:o})}))(s.image,s.classes);self.postMessage({type:"complete",target:s.elementIdToUpdate,targetType:s.targetType,updateLabels:s.updateLabels,data:t})}async function xt(s){let t=await(await rt.getInstance(o=>{self.postMessage({type:"download",task:"object-detection",data:o})}))(s.image,{threshold:.9,percentage:!0});self.postMessage({type:"complete",target:s.elementIdToUpdate,targetType:s.targetType,chartId:s.chartId,data:t})}
